{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:16:55.193947Z",
     "start_time": "2019-06-15T12:16:55.188927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 75346\n"
     ]
    }
   ],
   "source": [
    "with open(\"corpus02.txt\", encoding=\"utf8\") as fin:\n",
    "    text = fin.read()\n",
    "print(\"Number of characters: %d\" % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:15.584000Z",
     "start_time": "2019-06-15T12:26:15.456377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 11781\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# stopword_list = stopwords.words('english')\n",
    "\n",
    "raw_tokens = word_tokenize(text)\n",
    "tokens = []\n",
    "for token in raw_tokens:\n",
    "    if token.isalpha():\n",
    "#         if token.lower() not in stopword_list: \n",
    "        tokens.append(token.lower())\n",
    "print(\"Number of tokens: %d\" % len(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:18.964841Z",
     "start_time": "2019-06-15T12:26:18.958102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\t1167\n",
      "of\t801\n",
      "and\t360\n",
      "in\t299\n",
      "to\t279\n",
      "a\t173\n",
      "is\t138\n",
      "that\t128\n",
      "by\t123\n",
      "class\t104\n",
      "with\t101\n",
      "it\t100\n",
      "bourgeois\t99\n",
      "all\t98\n",
      "bourgeoisie\t92\n",
      "as\t86\n",
      "for\t84\n",
      "they\t83\n",
      "its\t81\n",
      "their\t80\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter(tokens)\n",
    "for w, c in word_counts.most_common(20):\n",
    "    print(\"%s\\t%d\" % (w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:22.227801Z",
     "start_time": "2019-06-15T12:26:22.206075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tthe\t244\n",
      "in\tthe\t91\n",
      "the\tbourgeoisie\t66\n",
      "the\tproletariat\t50\n",
      "to\tthe\t43\n",
      "by\tthe\t40\n",
      "for\tthe\t38\n",
      "of\tproduction\t38\n",
      "with\tthe\t34\n",
      "the\tbourgeois\t33\n",
      "conditions\tof\t29\n",
      "means\tof\t25\n",
      "of\tsociety\t24\n",
      "against\tthe\t23\n",
      "on\tthe\t23\n",
      "working\tclass\t23\n",
      "to\tbe\t22\n",
      "of\tall\t22\n",
      "is\tthe\t21\n",
      "the\tcommunists\t21\n"
     ]
    }
   ],
   "source": [
    "word_pair_counts = Counter()\n",
    "for i in range(len(tokens) - 1):\n",
    "    (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "    word_pair_counts[(w1, w2)] += 1\n",
    "    \n",
    "for pair, c in word_pair_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (pair[0], pair[1], c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the content in word_pair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:22:58.734759Z",
     "start_time": "2019-06-15T12:22:58.730362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('working', 'class'), 23)\n"
     ]
    }
   ],
   "source": [
    "print(word_pair_counts.most_common(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to get the contents in the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:25.580146Z",
     "start_time": "2019-06-15T12:26:25.573748Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tthe\t244\n",
      "in\tthe\t91\n",
      "the\tbourgeoisie\t66\n",
      "the\tproletariat\t50\n",
      "to\tthe\t43\n",
      "by\tthe\t40\n",
      "for\tthe\t38\n",
      "of\tproduction\t38\n",
      "with\tthe\t34\n",
      "the\tbourgeois\t33\n",
      "conditions\tof\t29\n",
      "means\tof\t25\n",
      "of\tsociety\t24\n",
      "against\tthe\t23\n",
      "on\tthe\t23\n",
      "working\tclass\t23\n",
      "to\tbe\t22\n",
      "of\tall\t22\n",
      "is\tthe\t21\n",
      "the\tcommunists\t21\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), c in word_pair_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (w1, w2, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:28.015904Z",
     "start_time": "2019-06-15T12:26:27.970859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\tclass\t23\n",
      "bourgeois\tsociety\t15\n",
      "class\tantagonisms\t11\n",
      "modern\tindustry\t11\n",
      "ruling\tclass\t11\n",
      "productive\tforces\t9\n",
      "modern\tbourgeois\t8\n",
      "middle\tages\t7\n",
      "bourgeois\tproperty\t7\n",
      "private\tproperty\t7\n",
      "feudal\tsociety\t6\n",
      "middle\tclass\t6\n",
      "social\tconditions\t6\n",
      "property\trelations\t6\n",
      "class\tstruggle\t6\n",
      "old\tsociety\t6\n",
      "petty\tbourgeois\t6\n",
      "existing\tsociety\t5\n",
      "one\tword\t5\n",
      "bourgeois\tsocialism\t5\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "word_pair_nosw_counts = Counter()\n",
    "for i in range(len(tokens) - 1):\n",
    "    (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "    if w1 not in stopword_list and w2 not in stopword_list:\n",
    "        word_pair_nosw_counts[(w1, w2)] += 1\n",
    "    \n",
    "for (w1, w2), c in word_pair_nosw_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (w1, w2, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent collocations with a distance of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:31.608811Z",
     "start_time": "2019-06-15T12:26:31.357196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\tof\t2\t302\n",
      "of\tthe\t1\t244\n",
      "the\tthe\t3\t186\n",
      "the\tthe\t8\t134\n",
      "the\tthe\t6\t129\n",
      "the\tthe\t7\t126\n",
      "the\tof\t3\t125\n",
      "the\tthe\t4\t117\n",
      "the\tthe\t5\t114\n",
      "of\tthe\t4\t92\n",
      "in\tthe\t1\t91\n",
      "of\tthe\t8\t91\n",
      "of\tthe\t6\t88\n",
      "the\tof\t7\t81\n",
      "the\tof\t6\t77\n",
      "of\tthe\t7\t76\n",
      "the\tof\t5\t76\n",
      "the\tof\t8\t75\n",
      "of\tthe\t5\t72\n",
      "the\tbourgeoisie\t1\t66\n"
     ]
    }
   ],
   "source": [
    "window_size = 9\n",
    "\n",
    "word_pair_counts = Counter()\n",
    "word_pair_distance_counts = Counter()\n",
    "for i in range(len(tokens) - 1):\n",
    "    for distance in range(1, window_size):\n",
    "        if i + distance < len(tokens):\n",
    "            w1 = tokens[i]\n",
    "            w2 = tokens[i + distance]\n",
    "            word_pair_distance_counts[(w1, w2, distance)] += 1\n",
    "            word_pair_counts[(w1, w2)] += 1\n",
    "\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%d\" % (w1, w2, distance, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an entry in word_pair_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:43.824216Z",
     "start_time": "2019-06-15T12:26:43.809379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('the', 'of', 2), 302)\n",
      "3\n",
      "0\n",
      "Occurrences of the word pair (the, of) with a distance of 1: 3\n",
      "Occurrences of the word pair (the, of) with a distance of 2: 302\n",
      "Occurrences of the word pair (the, of) with a distance of 3: 125\n",
      "Occurrences of the word pair (the, of) with a distance of 4: 59\n",
      "Occurrences of the word pair (the, of) with a distance of 5: 76\n",
      "Occurrences of the word pair (the, of) with a distance of 6: 77\n",
      "Occurrences of the word pair (the, of) with a distance of 7: 81\n",
      "Occurrences of the word pair (the, of) with a distance of 8: 75\n",
      "Occurrences of the usage 'the * * of'\n",
      "302\n",
      "Occurrences of the usage 'of * * the'\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(word_pair_distance_counts.most_common(1)[0])\n",
    "\n",
    "print(word_pair_distance_counts['the', 'of', 1])\n",
    "print(word_pair_distance_counts['the', 'of', 100])\n",
    "\n",
    "\n",
    "for distance in range(1, window_size):\n",
    "    print(\"Occurrences of the word pair (%s, %s) with a distance of %d: %d\" % (\n",
    "        'the', 'of', distance, word_pair_distance_counts['the', 'of', distance]))\n",
    "\n",
    "print(\"Occurrences of the usage 'the * * of'\")\n",
    "print(word_pair_distance_counts['the', 'of', 2])\n",
    "\n",
    "print(\"Occurrences of the usage 'of * * the'\")\n",
    "print(word_pair_distance_counts['of', 'the', 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the collocations with mean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:26:57.391904Z",
     "start_time": "2019-06-15T12:26:57.225336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tdestroyed\t8.000000\t3\n",
      "to\tpetty\t8.000000\t3\n",
      "necessarily\tof\t8.000000\t3\n",
      "in\tcommunistic\t8.000000\t2\n",
      "world\tand\t8.000000\t2\n",
      "and\texisting\t8.000000\t2\n",
      "is\tslave\t8.000000\t2\n",
      "an\teach\t8.000000\t2\n",
      "time\tsociety\t8.000000\t2\n",
      "an\tcommunication\t8.000000\t2\n",
      "every\twe\t8.000000\t2\n",
      "that\tword\t8.000000\t2\n",
      "bourgeoisie\tmarket\t8.000000\t2\n",
      "of\tfeet\t8.000000\t2\n",
      "population\tproperty\t8.000000\t2\n",
      "at\tthese\t8.000000\t2\n",
      "our\trelations\t8.000000\t2\n",
      "is\tsubsistence\t8.000000\t2\n",
      "disposal\tthe\t8.000000\t2\n",
      "wealth\tbourgeoisie\t8.000000\t2\n"
     ]
    }
   ],
   "source": [
    "pair_mean_distances = Counter()\n",
    "\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    pair_mean_distances[(w1, w2)] += distance * (c / word_pair_counts[(w1, w2)])\n",
    "\n",
    "for (w1, w2), distance in pair_mean_distances.most_common(20):\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering one-time cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:35:26.808407Z",
     "start_time": "2019-06-15T13:35:26.689996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tdestroyed\t8.000000\t3\n",
      "to\tpetty\t8.000000\t3\n",
      "necessarily\tof\t8.000000\t3\n",
      "in\tcommunistic\t8.000000\t2\n",
      "world\tand\t8.000000\t2\n",
      "and\texisting\t8.000000\t2\n",
      "is\tslave\t8.000000\t2\n",
      "an\teach\t8.000000\t2\n",
      "time\tsociety\t8.000000\t2\n",
      "an\tcommunication\t8.000000\t2\n",
      "every\twe\t8.000000\t2\n",
      "that\tword\t8.000000\t2\n",
      "bourgeoisie\tmarket\t8.000000\t2\n",
      "of\tfeet\t8.000000\t2\n",
      "population\tproperty\t8.000000\t2\n",
      "at\tthese\t8.000000\t2\n",
      "our\trelations\t8.000000\t2\n",
      "is\tsubsistence\t8.000000\t2\n",
      "disposal\tthe\t8.000000\t2\n",
      "wealth\tbourgeoisie\t8.000000\t2\n"
     ]
    }
   ],
   "source": [
    "pair_mean_distances = Counter()\n",
    "\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    if word_pair_counts[(w1, w2)] > 1:\n",
    "        pair_mean_distances[(w1, w2)] += distance * (c / word_pair_counts[(w1, w2)])\n",
    "\n",
    "for (w1, w2), distance in pair_mean_distances.most_common(20):\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:35:30.127374Z",
     "start_time": "2019-06-15T13:35:30.117116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continued\texistence\t1.000000\t2\n",
      "complete\tsystems\t1.000000\t2\n",
      "they\twish\t1.000000\t2\n",
      "new\tjerusalem\t1.000000\t2\n",
      "every\trevolutionary\t1.000000\t2\n",
      "revolutionary\tmovement\t1.000000\t2\n",
      "could\tbe\t1.000000\t2\n",
      "and\tothers\t1.000000\t2\n",
      "these\tsystems\t1.000000\t2\n",
      "social\tscience\t1.000000\t2\n",
      "most\tsuffering\t1.000000\t2\n",
      "suffering\tclass\t1.000000\t2\n",
      "antagonisms\tthey\t1.000000\t2\n",
      "their\tends\t1.000000\t2\n",
      "a\tcritical\t1.000000\t2\n",
      "these\tproposals\t1.000000\t2\n",
      "chiefly\tto\t1.000000\t2\n",
      "they\tsupport\t1.000000\t2\n",
      "partly\tof\t1.000000\t2\n",
      "existing\tsocial\t1.000000\t2\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), distance in pair_mean_distances.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:35:33.303459Z",
     "start_time": "2019-06-15T13:35:33.292672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which\tlaborer\t4.500000\t2\n",
      "in\tbare\t4.500000\t2\n",
      "a\texistence\t4.500000\t2\n",
      "means\tappropriation\t4.500000\t2\n",
      "intend\tthe\t4.500000\t2\n",
      "personal\tappropriation\t4.500000\t2\n",
      "labor\tappropriation\t4.500000\t2\n",
      "and\tleaves\t4.500000\t2\n",
      "away\tis\t4.500000\t2\n",
      "is\tfar\t4.500000\t2\n",
      "the\tliving\t4.500000\t2\n",
      "to\taccumulated\t4.500000\t2\n",
      "increase\tlabor\t4.500000\t2\n",
      "accumulated\tis\t4.500000\t2\n",
      "enrich\tthe\t4.500000\t2\n",
      "past\tsociety\t4.500000\t4\n",
      "dominates\tpresent\t4.500000\t2\n",
      "the\tperson\t4.500000\t2\n",
      "trade\tselling\t4.500000\t2\n",
      "but\tselling\t4.500000\t2\n"
     ]
    }
   ],
   "source": [
    "num_pairs = len(pair_mean_distances)\n",
    "mid = num_pairs // 2\n",
    "for (w1, w2), distance in pair_mean_distances.most_common()[mid-10:mid+10]:\n",
    "    print(\"%s\\t%s\\t%f\\t%d\" % (w1, w2, distance, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering with offset deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:35:36.531269Z",
     "start_time": "2019-06-15T13:35:36.380487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\tbranding\t4.500000\t4.949747\t2\n",
      "sketched\tthe\t4.500000\t4.949747\t2\n",
      "class\tstruggles\t4.500000\t4.949747\t2\n",
      "journeyman\tin\t4.500000\t4.949747\t2\n",
      "in\talmost\t4.500000\t4.949747\t2\n",
      "epochs\tof\t4.500000\t4.949747\t2\n",
      "everywhere\ta\t4.500000\t4.949747\t2\n",
      "old\tbourgeois\t4.500000\t4.949747\t2\n",
      "navigation\tand\t4.500000\t4.949747\t2\n",
      "vanished\tin\t4.500000\t4.949747\t2\n",
      "the\tgiant\t4.500000\t4.949747\t2\n",
      "the\tleaders\t4.500000\t4.949747\t2\n",
      "armies\tthe\t4.500000\t4.949747\t2\n",
      "its\tcapital\t4.500000\t4.949747\t2\n",
      "oppressed\tclass\t4.500000\t4.949747\t2\n",
      "the\texecutive\t4.500000\t4.949747\t2\n",
      "enthusiasm\tof\t4.500000\t4.949747\t2\n",
      "of\tegotistical\t4.500000\t4.949747\t2\n",
      "its\trelation\t4.500000\t4.949747\t2\n",
      "ones\tthat\t4.500000\t4.949747\t2\n"
     ]
    }
   ],
   "source": [
    "pair_deviations = Counter()\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    if word_pair_counts[(w1, w2)] > 1:\n",
    "        pair_deviations[(w1, w2)] += c * ((distance - pair_mean_distances[(w1, w2)]) ** 2)\n",
    "    \n",
    "for (w1, w2), dev_tmp in pair_deviations.most_common():\n",
    "    s_2 = dev_tmp / (word_pair_counts[(w1, w2)] - 1)\n",
    "    pair_deviations[(w1, w2)] = s_2 ** 0.5\n",
    "    \n",
    "for (w1, w2), dev in pair_deviations.most_common(20):\n",
    "    print(\"%s\\t%s\\t%f\\t%f\\t%d\" % (w1, w2, pair_mean_distances[(w1, w2)], dev, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:35:38.951614Z",
     "start_time": "2019-06-15T13:35:38.941003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "being\tclass\t4.000000\t0.000000\t2\n",
      "most\tsuffering\t1.000000\t0.000000\t2\n",
      "suffering\tclass\t1.000000\t0.000000\t2\n",
      "antagonisms\tthey\t1.000000\t0.000000\t2\n",
      "the\tappeal\t6.000000\t0.000000\t2\n",
      "they\tends\t5.000000\t0.000000\t2\n",
      "their\tends\t1.000000\t0.000000\t2\n",
      "a\tcritical\t1.000000\t0.000000\t2\n",
      "these\tproposals\t1.000000\t0.000000\t2\n",
      "of\tc\t6.000000\t0.000000\t2\n",
      "chiefly\tto\t1.000000\t0.000000\t2\n",
      "chiefly\tgermany\t2.000000\t0.000000\t2\n",
      "communists\tagainst\t6.000000\t0.000000\t2\n",
      "they\tsupport\t1.000000\t0.000000\t2\n",
      "partly\tof\t1.000000\t0.000000\t2\n",
      "partly\tin\t4.000000\t0.000000\t2\n",
      "germany\tfight\t2.000000\t0.000000\t2\n",
      "revolutionary\tagainst\t2.000000\t0.000000\t2\n",
      "germany\timmediately\t8.000000\t0.000000\t2\n",
      "existing\tsocial\t1.000000\t0.000000\t2\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), dev in pair_deviations.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%f\\t%f\\t%d\" % (w1, w2, pair_mean_distances[(w1, w2)], dev, word_pair_counts[(w1, w2)]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher supportive threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:35:42.721045Z",
     "start_time": "2019-06-15T13:35:42.636604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\tand\t3.833333\t1.466804\t12\n",
      "have\tof\t5.869565\t1.455533\t23\n",
      "to\tbe\t1.416667\t1.442120\t24\n",
      "the\tcommunism\t4.454545\t1.439697\t11\n",
      "of\tcan\t5.000000\t1.414214\t11\n",
      "in\tbut\t5.000000\t1.414214\t11\n",
      "for\ta\t2.076923\t1.382120\t13\n",
      "for\tclass\t5.363636\t1.361817\t11\n",
      "as\tand\t5.153846\t1.344504\t13\n",
      "has\tof\t5.730769\t1.343360\t26\n",
      "it\thas\t1.409091\t1.333063\t22\n",
      "working\tclass\t1.360000\t1.319091\t25\n",
      "in\tclass\t5.272727\t1.272078\t11\n",
      "bourgeois\tsociety\t1.312500\t1.250000\t16\n",
      "it\tof\t6.088235\t1.239933\t34\n",
      "by\tmeans\t1.692308\t0.947331\t13\n",
      "in\tproportion\t1.500000\t0.904534\t12\n",
      "they\tare\t1.250000\t0.866025\t12\n",
      "modern\tindustry\t1.166667\t0.577350\t12\n",
      "ruling\tclass\t1.000000\t0.000000\t11\n"
     ]
    }
   ],
   "source": [
    "pair_deviations = Counter()\n",
    "for (w1, w2, distance), c in word_pair_distance_counts.most_common():\n",
    "    if word_pair_counts[(w1, w2)] > 10:\n",
    "        pair_deviations[(w1, w2)] += c * ((distance - pair_mean_distances[(w1, w2)]) ** 2)\n",
    "    \n",
    "for (w1, w2), dev_tmp in pair_deviations.most_common():\n",
    "    s_2 = dev_tmp / (word_pair_counts[(w1, w2)] - 1)\n",
    "    pair_deviations[(w1, w2)] = s_2 ** 0.5\n",
    "    \n",
    "for (w1, w2), dev in pair_deviations.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%f\\t%f\\t%d\" % (w1, w2, pair_mean_distances[(w1, w2)], dev, word_pair_counts[(w1, w2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's Chi-Square Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:36:20.224571Z",
     "start_time": "2019-06-15T13:36:20.203547Z"
    }
   },
   "outputs": [],
   "source": [
    "word_pair_counts = Counter()\n",
    "word_counts = Counter(tokens)\n",
    "num_bigrams = 0\n",
    "\n",
    "for i in range(len(tokens) - 1):\n",
    "    w1 = tokens[i]\n",
    "    w2 = tokens[i + 1]\n",
    "    word_pair_counts[(w1, w2)] += 1\n",
    "    num_bigrams += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Square function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:36:25.276753Z",
     "start_time": "2019-06-15T13:36:25.272841Z"
    }
   },
   "outputs": [],
   "source": [
    "def chisquare(o11, o12, o21, o22):\n",
    "    n = o11 + o12 + o21 + o22\n",
    "    x_2 = (n * ((o11 * o22 - o12 * o21)**2)) / ((o11 + o12) * (o11 + o21) * (o12 + o22) * (o21 + o22)) \n",
    "    return x_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the chi-squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:36:27.748353Z",
     "start_time": "2019-06-15T13:36:27.716432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\testate\t2\t11780.000000\n",
      "constitution\tadapted\t2\t11780.000000\n",
      "karl\tmarx\t1\t11780.000000\n",
      "frederick\tengels\t1\t11780.000000\n",
      "czar\tmetternich\t1\t11780.000000\n",
      "police\tspies\t1\t11780.000000\n",
      "nursery\ttale\t1\t11780.000000\n",
      "italian\tflemish\t1\t11780.000000\n",
      "danish\tlanguages\t1\t11780.000000\n",
      "plebeian\tlord\t1\t11780.000000\n",
      "complicated\tarrangement\t1\t11780.000000\n",
      "manifold\tgradation\t1\t11780.000000\n",
      "patricians\tknights\t1\t11780.000000\n",
      "knights\tplebeians\t1\t11780.000000\n",
      "journeymen\tapprentices\t1\t11780.000000\n",
      "subordinate\tgradations\t1\t11780.000000\n",
      "cape\topened\t1\t11780.000000\n",
      "proper\tserving\t1\t11780.000000\n",
      "left\tremaining\t1\t11780.000000\n",
      "heavenly\tecstacies\t1\t11780.000000\n"
     ]
    }
   ],
   "source": [
    "pair_chi_squares = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    w1_only_count = word_counts[w1] - w1_w2_count\n",
    "    w2_only_count = word_counts[w2] - w1_w2_count\n",
    "    rest_count = num_bigrams - w1_only_count - w2_only_count - w1_w2_count\n",
    "    pair_chi_squares[(w1, w2)] = chisquare(w1_w2_count, w1_only_count, w2_only_count, rest_count)\n",
    "\n",
    "for (w1, w2), x_2 in pair_chi_squares.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on more frequent bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:36:47.157510Z",
     "start_time": "2019-06-15T13:36:47.146202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productive\tforces\t9\t9636.544203\n",
      "middle\tages\t7\t4928.714781\n",
      "no\tlonger\t14\t4150.496033\n",
      "working\tclass\t23\t2477.732678\n",
      "modern\tindustry\t11\t1128.037662\n",
      "class\tantagonisms\t11\t1042.736309\n",
      "private\tproperty\t7\t1022.522314\n",
      "ruling\tclass\t11\t966.767323\n",
      "can\tnot\t9\t775.745125\n",
      "their\town\t11\t759.449519\n",
      "proportion\tas\t8\t720.619853\n",
      "have\tbeen\t7\t702.438620\n",
      "it\thas\t20\t652.817376\n",
      "away\twith\t8\t563.758348\n",
      "to\tbe\t22\t468.075784\n",
      "just\tas\t6\t439.987822\n",
      "of\tthe\t244\t406.859323\n",
      "the\tbourgeoisie\t66\t397.199063\n",
      "its\town\t8\t392.296908\n",
      "petty\tbourgeois\t6\t381.069314\n"
     ]
    }
   ],
   "source": [
    "pair_chi_squares = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 5:\n",
    "        w1_only_count = word_counts[w1] - w1_w2_count\n",
    "        w2_only_count = word_counts[w2] - w1_w2_count\n",
    "        rest_count = num_bigrams - w1_only_count - w2_only_count - w1_w2_count\n",
    "        pair_chi_squares[(w1, w2)] = chisquare(w1_w2_count, w1_only_count, w2_only_count, rest_count)\n",
    "\n",
    "for (w1, w2), x_2 in pair_chi_squares.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:37:03.138427Z",
     "start_time": "2019-06-15T13:37:03.133313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\tthe\t21\t4.412587\n",
      "and\tby\t7\t2.913108\n",
      "at\tthe\t7\t2.592918\n",
      "and\tthat\t7\t2.542680\n",
      "be\tthe\t7\t2.367553\n",
      "proletariat\tthe\t10\t2.357617\n",
      "bourgeois\tthe\t6\t1.654642\n",
      "that\tof\t6\t0.910970\n",
      "and\tof\t20\t0.906966\n",
      "of\tclass\t9\t0.569228\n",
      "bourgeoisie\tthe\t7\t0.548588\n",
      "that\tthe\t15\t0.476118\n",
      "of\tits\t7\t0.436822\n",
      "and\tin\t11\t0.401790\n",
      "society\tthe\t6\t0.307430\n",
      "all\tthe\t11\t0.192300\n",
      "the\tproperty\t6\t0.041125\n",
      "and\tto\t9\t0.027804\n",
      "the\tclass\t10\t0.009971\n",
      "class\tthe\t10\t0.009971\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), x_2 in pair_chi_squares.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filtering out the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:38:03.955812Z",
     "start_time": "2019-06-15T13:38:03.941813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\testate\t2\t11780.000000\n",
      "constitution\tadapted\t2\t11780.000000\n",
      "productive\tforces\t9\t9636.544203\n",
      "eternal\ttruths\t3\t8834.249809\n",
      "corporate\tguilds\t2\t7852.666553\n",
      "absolute\tmonarchy\t4\t7537.599406\n",
      "eighteenth\tcentury\t3\t7066.799694\n",
      "immense\tmajority\t3\t6624.749575\n",
      "laid\tbare\t2\t5888.999830\n",
      "distinctive\tfeature\t2\t5234.221968\n",
      "torn\tasunder\t2\t5234.221968\n",
      "middle\tages\t7\t4928.714781\n",
      "radical\trupture\t2\t4710.799796\n",
      "buying\tdisappears\t2\t3925.333107\n",
      "let\tus\t3\t3310.499278\n",
      "upper\thand\t2\t2943.499745\n",
      "commercial\tcrises\t2\t2943.499745\n",
      "various\tstages\t2\t2943.499745\n",
      "united\taction\t3\t2942.749427\n",
      "raw\tmaterial\t2\t2616.221958\n"
     ]
    }
   ],
   "source": [
    "pair_chi_squares = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 1 and w1 not in stopword_list and w2 not in stopword_list:\n",
    "        w1_only_count = word_counts[w1] - w1_w2_count\n",
    "        w2_only_count = word_counts[w2] - w1_w2_count\n",
    "        rest_count = num_bigrams - w1_only_count - w2_only_count - w1_w2_count\n",
    "        pair_chi_squares[(w1, w2)] = chisquare(w1_w2_count, w1_only_count, w2_only_count, rest_count)\n",
    "\n",
    "for (w1, w2), x_2 in pair_chi_squares.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:38:08.529815Z",
     "start_time": "2019-06-15T13:38:08.524841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many\tbourgeois\t2\t49.412739\n",
      "bourgeois\tprivate\t2\t44.087627\n",
      "petty\tbourgeoisie\t2\t43.023037\n",
      "modern\tworking\t2\t41.985003\n",
      "bourgeois\tfreedom\t2\t39.732201\n",
      "revolutionary\tproletariat\t2\t35.100229\n",
      "old\tconditions\t2\t32.566311\n",
      "feudal\tproperty\t2\t31.386462\n",
      "old\tproperty\t2\t28.685615\n",
      "bourgeois\trevolution\t2\t26.136797\n",
      "modern\tbourgeoisie\t3\t21.380029\n",
      "whole\tbourgeoisie\t2\t20.752016\n",
      "revolutionary\tclass\t2\t20.224783\n",
      "bourgeois\tstate\t2\t17.063629\n",
      "every\tclass\t2\t16.075081\n",
      "bourgeois\tconditions\t3\t16.040705\n",
      "bourgeois\tform\t2\t14.680146\n",
      "one\tclass\t2\t10.562861\n",
      "bourgeois\tproduction\t2\t5.662454\n",
      "bourgeois\tclass\t3\t5.261506\n"
     ]
    }
   ],
   "source": [
    "for (w1, w2), x_2 in pair_chi_squares.most_common()[-20:]:\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for computing mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:38:11.336244Z",
     "start_time": "2019-06-15T13:38:11.332475Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def mutual_information(w1_w2_prob, w1_prob, w2_prob):\n",
    "    return math.log2(w1_w2_prob / (w1_prob * w2_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:38:14.509693Z",
     "start_time": "2019-06-15T13:38:14.484683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karl\tmarx\t1\t13.524297\n",
      "frederick\tengels\t1\t13.524297\n",
      "czar\tmetternich\t1\t13.524297\n",
      "police\tspies\t1\t13.524297\n",
      "nursery\ttale\t1\t13.524297\n",
      "italian\tflemish\t1\t13.524297\n",
      "danish\tlanguages\t1\t13.524297\n",
      "plebeian\tlord\t1\t13.524297\n",
      "complicated\tarrangement\t1\t13.524297\n",
      "manifold\tgradation\t1\t13.524297\n",
      "patricians\tknights\t1\t13.524297\n",
      "knights\tplebeians\t1\t13.524297\n",
      "journeymen\tapprentices\t1\t13.524297\n",
      "subordinate\tgradations\t1\t13.524297\n",
      "cape\topened\t1\t13.524297\n",
      "proper\tserving\t1\t13.524297\n",
      "left\tremaining\t1\t13.524297\n",
      "heavenly\tecstacies\t1\t13.524297\n",
      "chivalrous\tenthusiasm\t1\t13.524297\n",
      "egotistical\tcalculation\t1\t13.524297\n"
     ]
    }
   ],
   "source": [
    "num_unigrams = sum(word_counts.values())\n",
    "\n",
    "pair_mutual_information_scores = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 0:\n",
    "        w1_prob = word_counts[w1] / num_unigrams\n",
    "        w2_prob = word_counts[w2] / num_unigrams\n",
    "        w1_w2_prob = w1_w2_count / num_bigrams\n",
    "        pair_mutual_information_scores[(w1, w2)] = mutual_information(w1_w2_prob, w1_prob, w2_prob)\n",
    "\n",
    "for (w1, w2), mi in pair_mutual_information_scores.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], mi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:38:17.447216Z",
     "start_time": "2019-06-15T13:38:17.436236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productive\tforces\t9\t10.064865\n",
      "middle\tages\t7\t9.461287\n",
      "no\tlonger\t14\t8.215308\n",
      "private\tproperty\t7\t7.202369\n",
      "working\tclass\t23\t6.762457\n",
      "modern\tindustry\t11\t6.699483\n",
      "have\tbeen\t7\t6.669874\n",
      "class\tantagonisms\t11\t6.582849\n",
      "proportion\tas\t8\t6.513070\n",
      "ruling\tclass\t11\t6.475934\n",
      "can\tnot\t9\t6.453431\n",
      "just\tas\t6\t6.223563\n",
      "away\twith\t8\t6.165646\n",
      "their\town\t11\t6.138238\n",
      "petty\tbourgeois\t6\t6.020471\n",
      "middle\tclass\t6\t5.708380\n",
      "its\town\t8\t5.660885\n",
      "property\trelations\t6\t5.658048\n",
      "not\tonly\t7\t5.550292\n",
      "class\tstruggle\t6\t5.321357\n"
     ]
    }
   ],
   "source": [
    "num_unigrams = sum(word_counts.values())\n",
    "\n",
    "pair_mutual_information_scores = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 5:\n",
    "        w1_prob = word_counts[w1] / num_unigrams\n",
    "        w2_prob = word_counts[w2] / num_unigrams\n",
    "        w1_w2_prob = w1_w2_count / num_bigrams\n",
    "        pair_mutual_information_scores[(w1, w2)] = mutual_information(w1_w2_prob, w1_prob, w2_prob)\n",
    "\n",
    "for (w1, w2), mi in pair_mutual_information_scores.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], mi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filtering out the collocations containing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:38:21.355631Z",
     "start_time": "2019-06-15T13:38:21.340395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\testate\t2\t12.524297\n",
      "constitution\tadapted\t2\t12.524297\n",
      "corporate\tguilds\t2\t11.939334\n",
      "eternal\ttruths\t3\t11.524297\n",
      "laid\tbare\t2\t11.524297\n",
      "distinctive\tfeature\t2\t11.354372\n",
      "torn\tasunder\t2\t11.354372\n",
      "eighteenth\tcentury\t3\t11.202369\n",
      "radical\trupture\t2\t11.202369\n",
      "immense\tmajority\t3\t11.109259\n",
      "buying\tdisappears\t2\t10.939334\n",
      "absolute\tmonarchy\t4\t10.880441\n",
      "upper\thand\t2\t10.524297\n",
      "commercial\tcrises\t2\t10.524297\n",
      "various\tstages\t2\t10.524297\n",
      "earlier\tepochs\t2\t10.354372\n",
      "raw\tmaterial\t2\t10.354372\n",
      "complete\tsystems\t2\t10.354372\n",
      "guild\tmasters\t2\t10.202369\n",
      "best\tpossible\t2\t10.202369\n"
     ]
    }
   ],
   "source": [
    "num_unigrams = sum(word_counts.values())\n",
    "\n",
    "pair_mutual_information_scores = Counter()\n",
    "for (w1, w2), w1_w2_count in word_pair_counts.most_common():\n",
    "    if w1_w2_count > 1 and w1 not in stopword_list and w2 not in stopword_list:\n",
    "        w1_prob = word_counts[w1] / num_unigrams\n",
    "        w2_prob = word_counts[w2] / num_unigrams\n",
    "        w1_w2_prob = w1_w2_count / num_bigrams\n",
    "        pair_mutual_information_scores[(w1, w2)] = mutual_information(w1_w2_prob, w1_prob, w2_prob)\n",
    "\n",
    "for (w1, w2), mi in pair_mutual_information_scores.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\\t%f\" % (w1, w2, word_pair_counts[(w1, w2)], mi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
