{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec Basic\n",
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T04:01:51.788204Z",
     "start_time": "2019-06-14T04:01:51.020339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>店家很給力，快遞也是相當快，第三次光顧啦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>這樣的配置用Vista系統還是有點卡。 指紋收集器。 沒送原裝滑鼠還需要自己買，不太好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>不錯，在同等檔次酒店中應該是值得推薦的！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>哎！ 不會是蒙牛乾的吧 嚴懲真凶！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>空尤其是三立電視臺女主播做的序尤其無趣像是硬湊那麼多字</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag                                          text\n",
       "0   P                          店家很給力，快遞也是相當快，第三次光顧啦\n",
       "1   N  這樣的配置用Vista系統還是有點卡。 指紋收集器。 沒送原裝滑鼠還需要自己買，不太好。\n",
       "2   P                          不錯，在同等檔次酒店中應該是值得推薦的！\n",
       "3   N                             哎！ 不會是蒙牛乾的吧 嚴懲真凶！\n",
       "4   N                   空尤其是三立電視臺女主播做的序尤其無趣像是硬湊那麼多字"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/sentiment.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T04:01:56.421000Z",
     "start_time": "2019-06-14T04:01:56.409340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6388\n",
      "N    3347\n",
      "P    3041\n",
      "Name: tag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df['tag'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T04:02:01.610634Z",
     "start_time": "2019-06-14T04:01:59.525218Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/0p/7xy1_dzx0_s5rnf06c0b316w0000gn/T/jieba.cache\n",
      "Loading model cost 0.653 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>店家很給力，快遞也是相當快，第三次光顧啦</td>\n",
       "      <td>[店家, 很, 給力, ，, 快遞, 也, 是, 相當快, ，, 第三次, 光顧, 啦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>這樣的配置用Vista系統還是有點卡。 指紋收集器。 沒送原裝滑鼠還需要自己買，不太好。</td>\n",
       "      <td>[這樣, 的, 配置, 用, Vista, 系統, 還是, 有點, 卡, 。,  , 指紋,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>不錯，在同等檔次酒店中應該是值得推薦的！</td>\n",
       "      <td>[不錯, ，, 在, 同等, 檔次, 酒店, 中應, 該, 是, 值得, 推薦, 的, ！]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>哎！ 不會是蒙牛乾的吧 嚴懲真凶！</td>\n",
       "      <td>[哎, ！,  , 不會, 是, 蒙牛, 乾, 的, 吧,  , 嚴懲, 真凶, ！]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>空尤其是三立電視臺女主播做的序尤其無趣像是硬湊那麼多字</td>\n",
       "      <td>[空, 尤其, 是, 三立, 電視, 臺, 女主播, 做, 的, 序, 尤其, 無趣, 像是...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag                                          text  \\\n",
       "0   P                          店家很給力，快遞也是相當快，第三次光顧啦   \n",
       "1   N  這樣的配置用Vista系統還是有點卡。 指紋收集器。 沒送原裝滑鼠還需要自己買，不太好。   \n",
       "2   P                          不錯，在同等檔次酒店中應該是值得推薦的！   \n",
       "3   N                             哎！ 不會是蒙牛乾的吧 嚴懲真凶！   \n",
       "4   N                   空尤其是三立電視臺女主播做的序尤其無趣像是硬湊那麼多字   \n",
       "\n",
       "                                          token_text  \n",
       "0       [店家, 很, 給力, ，, 快遞, 也, 是, 相當快, ，, 第三次, 光顧, 啦]  \n",
       "1  [這樣, 的, 配置, 用, Vista, 系統, 還是, 有點, 卡, 。,  , 指紋,...  \n",
       "2     [不錯, ，, 在, 同等, 檔次, 酒店, 中應, 該, 是, 值得, 推薦, 的, ！]  \n",
       "3        [哎, ！,  , 不會, 是, 蒙牛, 乾, 的, 吧,  , 嚴懲, 真凶, ！]  \n",
       "4  [空, 尤其, 是, 三立, 電視, 臺, 女主播, 做, 的, 序, 尤其, 無趣, 像是...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "df['token_text'] = df['text'].apply(lambda x:list(jieba.cut(x)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T04:02:08.708548Z",
     "start_time": "2019-06-14T04:02:05.825708Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(df['token_text'], min_count=1, size=300, window=5, sg=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T16:45:33.030707Z",
     "start_time": "2019-06-14T16:45:23.864993Z"
    }
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T16:47:13.934580Z",
     "start_time": "2019-06-14T16:47:13.844999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('結婚然', 0.6256321668624878), ('生小孩', 0.624354362487793), ('結婚過', 0.620686948299408), ('想結', 0.6196929216384888), ('不結', 0.6189882159233093), ('嫁娶', 0.6148558259010315), ('有計畫', 0.6132557392120361), ('要結', 0.6122066974639893), ('先買房', 0.6104307174682617), ('成家', 0.609870433807373), ('再結', 0.608663022518158), ('結婚後來', 0.6075947284698486), ('裸婚', 0.6005551218986511), ('今年年底', 0.596331775188446), ('會結', 0.5920178890228271), ('結婚現', 0.5911446809768677), ('當結婚', 0.5892318487167358), ('生女兒', 0.5877693295478821), ('奉子成婚', 0.5866853594779968), ('試婚', 0.5865316987037659)]\n",
      "----------------------------------------\n",
      "[('結婚然', 0.6303492784500122), ('生小孩', 0.6300292611122131), ('嫁娶', 0.6172428727149963), ('步入', 0.6136747598648071), ('有結', 0.6112129092216492), ('奉子成婚', 0.6074534058570862), ('結婚過', 0.6059277057647705), ('之後結婚', 0.6053087115287781), ('禮堂', 0.6033338308334351), ('婚生', 0.6031174659729004), ('明年初', 0.6030763387680054), ('結婚且', 0.6014657616615295), ('親事', 0.600039541721344), ('婚生子', 0.5996357798576355), ('想結', 0.5995362997055054), ('要結', 0.5994835495948792), ('談結婚', 0.5975024700164795), ('結婚生', 0.596755862236023), ('不結', 0.595413088798523), ('結婚後來', 0.5944710969924927)]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirlong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jirlong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['結婚', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['結婚', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T16:46:32.981578Z",
     "start_time": "2019-06-14T16:46:30.428175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirlong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jirlong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "[('不愛吃', 0.6662341952323914), ('海鮮', 0.6537903547286987), ('吃', 0.6478301286697388), ('不新鮮', 0.6473957300186157), ('我愛吃', 0.645952045917511), ('燒肉', 0.6451542973518372), ('愛吃', 0.6437597274780273), ('生魚片', 0.6403005123138428), ('很愛吃', 0.6384100914001465), ('沒吃過', 0.6372779607772827)]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirlong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word '工程師' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1267e36b66e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'好吃'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'工程師'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'他'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'她'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'工程師'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'她'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'他'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 )\n\u001b[0;32m-> 1398\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \"\"\"\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word '工程師' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print(len(model['好吃']))\n",
    "print(model.most_similar('好吃'))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['工程師', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['工程師', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['科學家', '男'], negative=['女'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['科學家', '女'], negative=['男'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['醫生', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['醫生', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['家長', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['家長', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['結婚', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['結婚', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['同性', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['同性', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['同志', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['同志', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['不婚', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['不婚', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['未婚', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['未婚', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['成功', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['成功', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['外遇', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['外遇', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['離婚', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['離婚', '她'], negative=['他'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['失敗', '他'], negative=['她'], topn=20))\n",
    "print(\"-\"*40)\n",
    "print(model.most_similar(positive=['失敗', '她'], negative=['他'], topn=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T04:02:31.267705Z",
     "start_time": "2019-06-14T04:02:25.523788Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"data/CBOW_iter15_2017-2018.bin\", binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T04:03:06.974560Z",
     "start_time": "2019-06-14T04:03:06.971255Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-8-e3fead0f3b67>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e3fead0f3b67>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(model.most_similar(~'工程師' - \"她\" + \"他\")\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "print(len(model['好吃']))\n",
    "print(model.most_similar('好吃'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R RDS to word2vec model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RDS to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T14:52:51.410627Z",
     "start_time": "2019-06-14T14:52:19.584381Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install pyreadr\n",
    "import pyreadr\n",
    "result = pyreadr.read_r('../R/Crawler/boy-girl_201904121250.rda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T14:52:54.784051Z",
     "start_time": "2019-06-14T14:52:54.779216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['allc.df', 'allp.df'])\n",
      "Index(['plink', 'board', 'pcontent', 'poster', 'ptitle', 'ptime'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(result.keys())\n",
    "post = result[\"allp.df\"]\n",
    "print(post.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing post content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T14:53:01.832782Z",
     "start_time": "2019-06-14T14:52:59.684687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plink</th>\n",
       "      <th>board</th>\n",
       "      <th>pcontent</th>\n",
       "      <th>poster</th>\n",
       "      <th>ptitle</th>\n",
       "      <th>ptime</th>\n",
       "      <th>ptext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ptt.cc/bbs/Boy-Girl/M.1165687832.A...</td>\n",
       "      <td>Boy-Girl</td>\n",
       "      <td>\\n我記得我前男友影響我最深的就是：\\n\\n別人的感情世界不要管、不要插手、不要評論\\n\\n...</td>\n",
       "      <td>candyzz (嚕拉拉)</td>\n",
       "      <td>大小姐</td>\n",
       "      <td>Sun Dec 10 02:37:15 2006</td>\n",
       "      <td>我記得我前男友影響我最深的就是：別人的感情世界不要管、不要插手、不要評論*-*因為女生很容易...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ptt.cc/bbs/Boy-Girl/M.1166975303.A...</td>\n",
       "      <td>Boy-Girl</td>\n",
       "      <td>\\n我和她 已經交往快8年了 從國二開始認識 一直到大四上學期的今天聖誕夜\\n\\n想起一開始...</td>\n",
       "      <td>abcc122333 (小巴)</td>\n",
       "      <td>[分享]她答應了!她答應了!</td>\n",
       "      <td>Mon Dec 25 01:11:34 2006</td>\n",
       "      <td>我和她已經交往快8年了從國二開始認識一直到大四上學期的今天聖誕夜想起一開始我們還經常鬥嘴誇口...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ptt.cc/bbs/Boy-Girl/M.1167097252.A...</td>\n",
       "      <td>Boy-Girl</td>\n",
       "      <td>\\n\\n\\n\\n故事是這樣的\\n\\n男生希望女生來找他 兩個人為了早一個小時 晚一個小時\\n...</td>\n",
       "      <td>soppy158 (Rosy)</td>\n",
       "      <td>(兩性成長)兩性平等與錯誤投射</td>\n",
       "      <td>Tue Dec 26 10:11:03 2006</td>\n",
       "      <td>故事是這樣的男生希望女生來找他兩個人為了早一個小時晚一個小時爭執不休吵架時間就已經多過這一個...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ptt.cc/bbs/Boy-Girl/M.1168227921.A...</td>\n",
       "      <td>Boy-Girl</td>\n",
       "      <td>\\n從小學開始 正常人都會對男女有好奇心 但我們都不成熟   對了 健康第一^O^\\n\\n甚...</td>\n",
       "      <td>voicespq (男稿的人)</td>\n",
       "      <td>[分享]人際關係 永續發展</td>\n",
       "      <td>Mon Jan  8 11:45:20 2007</td>\n",
       "      <td>從小學開始正常人都會對男女有好奇心但我們都不成熟對了健康第一^O^甚至大人都有不成熟之時所以...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ptt.cc/bbs/Boy-Girl/M.1168753589.A...</td>\n",
       "      <td>Boy-Girl</td>\n",
       "      <td>\\n前陣子我家閃光一直叫我去玩\\n\\n但是我對這種打打殺殺的遊戲非常沒興趣\\n\\n所以就一直...</td>\n",
       "      <td>flower319 (*花*)</td>\n",
       "      <td>[討論] 我該怎樣跟我家閃光開口</td>\n",
       "      <td>Sun Jan 14 13:46:24 2007</td>\n",
       "      <td>前陣子我家閃光一直叫我去玩但是我對這種打打殺殺的遊戲非常沒興趣所以就一直拒絕但是他一直遊說我...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               plink     board  \\\n",
       "0  https://www.ptt.cc/bbs/Boy-Girl/M.1165687832.A...  Boy-Girl   \n",
       "1  https://www.ptt.cc/bbs/Boy-Girl/M.1166975303.A...  Boy-Girl   \n",
       "2  https://www.ptt.cc/bbs/Boy-Girl/M.1167097252.A...  Boy-Girl   \n",
       "3  https://www.ptt.cc/bbs/Boy-Girl/M.1168227921.A...  Boy-Girl   \n",
       "4  https://www.ptt.cc/bbs/Boy-Girl/M.1168753589.A...  Boy-Girl   \n",
       "\n",
       "                                            pcontent           poster  \\\n",
       "0  \\n我記得我前男友影響我最深的就是：\\n\\n別人的感情世界不要管、不要插手、不要評論\\n\\n...    candyzz (嚕拉拉)   \n",
       "1  \\n我和她 已經交往快8年了 從國二開始認識 一直到大四上學期的今天聖誕夜\\n\\n想起一開始...  abcc122333 (小巴)   \n",
       "2  \\n\\n\\n\\n故事是這樣的\\n\\n男生希望女生來找他 兩個人為了早一個小時 晚一個小時\\n...  soppy158 (Rosy)   \n",
       "3  \\n從小學開始 正常人都會對男女有好奇心 但我們都不成熟   對了 健康第一^O^\\n\\n甚...  voicespq (男稿的人)   \n",
       "4  \\n前陣子我家閃光一直叫我去玩\\n\\n但是我對這種打打殺殺的遊戲非常沒興趣\\n\\n所以就一直...  flower319 (*花*)   \n",
       "\n",
       "             ptitle                     ptime  \\\n",
       "0               大小姐  Sun Dec 10 02:37:15 2006   \n",
       "1    [分享]她答應了!她答應了!  Mon Dec 25 01:11:34 2006   \n",
       "2   (兩性成長)兩性平等與錯誤投射  Tue Dec 26 10:11:03 2006   \n",
       "3     [分享]人際關係 永續發展  Mon Jan  8 11:45:20 2007   \n",
       "4  [討論] 我該怎樣跟我家閃光開口  Sun Jan 14 13:46:24 2007   \n",
       "\n",
       "                                               ptext  \n",
       "0  我記得我前男友影響我最深的就是：別人的感情世界不要管、不要插手、不要評論*-*因為女生很容易...  \n",
       "1  我和她已經交往快8年了從國二開始認識一直到大四上學期的今天聖誕夜想起一開始我們還經常鬥嘴誇口...  \n",
       "2  故事是這樣的男生希望女生來找他兩個人為了早一個小時晚一個小時爭執不休吵架時間就已經多過這一個...  \n",
       "3  從小學開始正常人都會對男女有好奇心但我們都不成熟對了健康第一^O^甚至大人都有不成熟之時所以...  \n",
       "4  前陣子我家閃光一直叫我去玩但是我對這種打打殺殺的遊戲非常沒興趣所以就一直拒絕但是他一直遊說我...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "post['ptext'] = post['pcontent'].apply(lambda x:x.replace(\"\\n\", \"\"))\n",
    "post['ptext'] = post['ptext'].apply(lambda x:re.sub(\"\\s\", \"\", x))\n",
    "post.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:00:55.671671Z",
     "start_time": "2019-06-14T15:00:55.661804Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jeiba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4b9dd8320f25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjeiba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"你最近好嗎？\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'jeiba' is not defined"
     ]
    }
   ],
   "source": [
    "jeiba.cut(\"你最近好嗎？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:01:56.314559Z",
     "start_time": "2019-06-14T15:01:56.310003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87276"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post[\"ptext\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:21:54.201785Z",
     "start_time": "2019-06-14T15:11:48.774881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "token_post = []\n",
    "i = 0\n",
    "for p in post['ptext']:\n",
    "    token_post.append(list(jieba.cut(p)))\n",
    "    i += 1\n",
    "    if(i%1000 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T16:20:18.254975Z",
     "start_time": "2019-06-14T16:20:18.244123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我',\n",
       " '和',\n",
       " '她',\n",
       " '已經',\n",
       " '交往',\n",
       " '快',\n",
       " '8',\n",
       " '年',\n",
       " '了',\n",
       " '從',\n",
       " '國二開始',\n",
       " '認識',\n",
       " '一直',\n",
       " '到',\n",
       " '大四',\n",
       " '上學期',\n",
       " '的',\n",
       " '今天',\n",
       " '聖誕夜',\n",
       " '想起',\n",
       " '一開始',\n",
       " '我們',\n",
       " '還經常鬥',\n",
       " '嘴',\n",
       " '誇口',\n",
       " '絕對',\n",
       " '不會',\n",
       " '喜歡',\n",
       " '上',\n",
       " '對方',\n",
       " '但',\n",
       " '相處',\n",
       " '越久越',\n",
       " '發現',\n",
       " '自己',\n",
       " '不能',\n",
       " '沒有',\n",
       " '彼此',\n",
       " '當時',\n",
       " '我',\n",
       " '這個',\n",
       " '毛頭',\n",
       " '小子',\n",
       " '為',\n",
       " '了',\n",
       " '打動',\n",
       " '她',\n",
       " '芳',\n",
       " '心想',\n",
       " '盡辦法',\n",
       " '最',\n",
       " '後',\n",
       " '我',\n",
       " '做出',\n",
       " '了',\n",
       " '一個',\n",
       " '硫酸',\n",
       " '銅藍色',\n",
       " '斜晶體',\n",
       " '就',\n",
       " '像',\n",
       " '一顆',\n",
       " '海洋',\n",
       " '之星',\n",
       " '般地',\n",
       " '送給',\n",
       " '她',\n",
       " '我終',\n",
       " '於',\n",
       " '得到',\n",
       " '她',\n",
       " '的',\n",
       " '心',\n",
       " '....',\n",
       " '高中',\n",
       " '時',\n",
       " '她',\n",
       " '考上',\n",
       " '了',\n",
       " '台北',\n",
       " '的',\n",
       " '學校',\n",
       " '我則',\n",
       " '繼續',\n",
       " '留在',\n",
       " '中壢',\n",
       " '大學',\n",
       " '我',\n",
       " '考上',\n",
       " '台中',\n",
       " '而',\n",
       " '她則',\n",
       " '是',\n",
       " '出國',\n",
       " '留學',\n",
       " '修習',\n",
       " '國際',\n",
       " '貿易',\n",
       " '這段',\n",
       " '日子',\n",
       " '我們',\n",
       " '經常',\n",
       " '是',\n",
       " '利用',\n",
       " 'MSN',\n",
       " '聯絡',\n",
       " '感情',\n",
       " '她',\n",
       " '在',\n",
       " '國外',\n",
       " '的',\n",
       " '生活',\n",
       " '支出',\n",
       " '幾乎',\n",
       " '都',\n",
       " '由',\n",
       " '我',\n",
       " '來',\n",
       " '支付',\n",
       " '(',\n",
       " '我',\n",
       " '家境',\n",
       " '算不錯',\n",
       " ')',\n",
       " '而',\n",
       " '她',\n",
       " '也',\n",
       " '因為',\n",
       " '成績',\n",
       " '優異',\n",
       " '提前',\n",
       " '在',\n",
       " '大四',\n",
       " '上',\n",
       " '畢業',\n",
       " '今天',\n",
       " '聖誕夜',\n",
       " '她',\n",
       " '特地',\n",
       " '下台',\n",
       " '中',\n",
       " '陪',\n",
       " '我',\n",
       " 'ㄧ',\n",
       " '起度過',\n",
       " '晚上',\n",
       " '我載',\n",
       " '她',\n",
       " '到',\n",
       " '台',\n",
       " '中',\n",
       " '梧棲港',\n",
       " '去',\n",
       " '吃',\n",
       " '海鮮',\n",
       " '但',\n",
       " '店家',\n",
       " '早早',\n",
       " '收攤',\n",
       " '我們',\n",
       " '倆',\n",
       " '只好',\n",
       " '在',\n",
       " '魚港邊',\n",
       " '散步',\n",
       " '我們',\n",
       " '開心',\n",
       " '的',\n",
       " '聊著',\n",
       " '就',\n",
       " '在',\n",
       " '話',\n",
       " '題間',\n",
       " '幾秒',\n",
       " '中',\n",
       " '的',\n",
       " '沉默',\n",
       " '我',\n",
       " '鼓起',\n",
       " '勇氣問',\n",
       " ':',\n",
       " '\"',\n",
       " '小彤',\n",
       " '(',\n",
       " '銅',\n",
       " ')',\n",
       " '在',\n",
       " '這梧',\n",
       " '棲港',\n",
       " '我',\n",
       " '有',\n",
       " '個',\n",
       " '問題',\n",
       " '想問',\n",
       " '妳',\n",
       " '...',\n",
       " '你',\n",
       " '願',\n",
       " '意當',\n",
       " '吾妻',\n",
       " '(',\n",
       " '梧棲',\n",
       " ')',\n",
       " '嗎',\n",
       " '?',\n",
       " '...',\n",
       " '你',\n",
       " '願',\n",
       " '意當',\n",
       " '我',\n",
       " '妻子',\n",
       " '嗎',\n",
       " '?',\n",
       " '\"',\n",
       " '我',\n",
       " '當時',\n",
       " '真是',\n",
       " '用',\n",
       " '盡',\n",
       " '了',\n",
       " '勇氣',\n",
       " '才',\n",
       " '問出',\n",
       " '了',\n",
       " '這句',\n",
       " '話',\n",
       " '因為',\n",
       " '我',\n",
       " '很',\n",
       " '清楚',\n",
       " '她',\n",
       " '實在',\n",
       " '比',\n",
       " '我',\n",
       " '優秀太多',\n",
       " '了',\n",
       " '我',\n",
       " '怕',\n",
       " '我',\n",
       " '配不上',\n",
       " '她',\n",
       " '另一方面',\n",
       " '我',\n",
       " '又',\n",
       " '怕',\n",
       " '她',\n",
       " '答應',\n",
       " '是',\n",
       " '為',\n",
       " '了',\n",
       " '報答',\n",
       " '我',\n",
       " '對',\n",
       " '她',\n",
       " '在',\n",
       " '國外',\n",
       " '的',\n",
       " '生活',\n",
       " '資助',\n",
       " '這樣',\n",
       " '我會',\n",
       " '更',\n",
       " '傷心',\n",
       " '就',\n",
       " '在',\n",
       " '這驚疑',\n",
       " '不定',\n",
       " '的',\n",
       " '當下',\n",
       " '她',\n",
       " '抱住',\n",
       " '了',\n",
       " '我',\n",
       " '在',\n",
       " '我',\n",
       " '耳邊',\n",
       " '輕聲',\n",
       " '說',\n",
       " ':',\n",
       " '\"',\n",
       " 'Ido',\n",
       " '!',\n",
       " '\"',\n",
       " '我',\n",
       " '飆出',\n",
       " '了',\n",
       " '眼淚',\n",
       " '呆',\n",
       " '了',\n",
       " '5',\n",
       " '秒',\n",
       " '鐘後直問',\n",
       " ':',\n",
       " '\"',\n",
       " '真的',\n",
       " '嗎',\n",
       " '?',\n",
       " '你',\n",
       " '願意',\n",
       " '?',\n",
       " '\"',\n",
       " '\"',\n",
       " '是',\n",
       " '阿',\n",
       " '我',\n",
       " '一直',\n",
       " '在',\n",
       " '等',\n",
       " '你',\n",
       " '說',\n",
       " '這句',\n",
       " '話',\n",
       " '看',\n",
       " '你',\n",
       " '什麼',\n",
       " '時候',\n",
       " '想',\n",
       " '把',\n",
       " '我',\n",
       " '套住',\n",
       " '^',\n",
       " '^',\n",
       " '\"',\n",
       " '原來',\n",
       " '我',\n",
       " '多慮',\n",
       " '了',\n",
       " '她',\n",
       " '一直',\n",
       " '在',\n",
       " '等',\n",
       " '我',\n",
       " '今天',\n",
       " '我終',\n",
       " '於',\n",
       " '得償',\n",
       " '心願',\n",
       " '了',\n",
       " '今年',\n",
       " '聖誕夜',\n",
       " '我永遠',\n",
       " '不會',\n",
       " '忘',\n",
       " '記後記',\n",
       " '在',\n",
       " '她',\n",
       " '答應',\n",
       " '之',\n",
       " '後',\n",
       " '我們',\n",
       " '抱',\n",
       " '在',\n",
       " '一起',\n",
       " '不',\n",
       " '知道',\n",
       " '過了',\n",
       " '多久',\n",
       " '後',\n",
       " '面',\n",
       " '竟然',\n",
       " '傳來',\n",
       " '一聲',\n",
       " '\"',\n",
       " 'MerryChristmas',\n",
       " '!',\n",
       " '呵呵',\n",
       " '呵呵',\n",
       " '!',\n",
       " '\"',\n",
       " '我',\n",
       " '和',\n",
       " '她',\n",
       " '滿臉',\n",
       " '黑線',\n",
       " '往後瞧',\n",
       " '竟然',\n",
       " '發現',\n",
       " '...',\n",
       " '哇',\n",
       " '咧',\n",
       " '!',\n",
       " '梧棲港',\n",
       " '竟然',\n",
       " '也',\n",
       " '有',\n",
       " '聖誕',\n",
       " '老公公',\n",
       " '啦',\n",
       " '!',\n",
       " '緊接',\n",
       " '著',\n",
       " '老公公',\n",
       " '後',\n",
       " '面',\n",
       " '想起',\n",
       " '一陣',\n",
       " '嬉鬧',\n",
       " '跟',\n",
       " '掌聲',\n",
       " '原來',\n",
       " '這位',\n",
       " '扮',\n",
       " '老公公',\n",
       " '的',\n",
       " '同',\n",
       " '協玩大',\n",
       " '冒險輸',\n",
       " '了',\n",
       " '要',\n",
       " '扮',\n",
       " '聖誕',\n",
       " '老公公',\n",
       " '跟路',\n",
       " '人',\n",
       " '說',\n",
       " '聖誕',\n",
       " '快樂',\n",
       " '我',\n",
       " '當時',\n",
       " '好像',\n",
       " '做',\n",
       " '了',\n",
       " '虧',\n",
       " '心事',\n",
       " '地',\n",
       " '不知',\n",
       " '如何是好',\n",
       " '結果',\n",
       " '她',\n",
       " '說',\n",
       " '就',\n",
       " '當作',\n",
       " '你',\n",
       " '求婚',\n",
       " '的',\n",
       " '見',\n",
       " '證人',\n",
       " '吧',\n",
       " 'orz',\n",
       " '...',\n",
       " '她',\n",
       " '竟然',\n",
       " '還那',\n",
       " '一群',\n",
       " '同協',\n",
       " '說',\n",
       " '我們',\n",
       " '倆',\n",
       " '剛剛',\n",
       " '在',\n",
       " '這做',\n",
       " '的',\n",
       " '約定',\n",
       " '羞死',\n",
       " '人',\n",
       " '了',\n",
       " '>',\n",
       " '/',\n",
       " '/',\n",
       " '/',\n",
       " '<',\n",
       " '-',\n",
       " '-',\n",
       " '◆',\n",
       " 'From',\n",
       " ':',\n",
       " '222.157',\n",
       " '.',\n",
       " '160.16']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_post[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:01:48.950829Z",
     "start_time": "2019-06-14T16:58:52.025391Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(token_post, min_count=20, size=300, window=8, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Pretrained - eland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_tw = KeyedVectors.load_word2vec_format(\"data/CBOW_iter15_2017-2018.bin\", binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case: 罷工 #protest and social movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_tw.most_similar('罷工', topn = 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_tw.most_similar('抗爭', topn = 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case: gender stereotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = [\"她\", \"妳\", \"女生\", \"女孩\", \"女士\", \"女人\", \"婦人\", \"婦\", \"女\", \"婦女\",\\\n",
    "          \"女性\", \"女孩子\", \"她們\", \"媽媽\", \"女兒\", \"女子\",\"人妻\", \"姊姊\", \"姐姐\",\\\n",
    "          \"妹妹\", \"少婦\", \"熟女\", \"小女孩\", \"母親\", \"表妹\", \"姪女\", \"婆婆\", \"閨蜜\",\\\n",
    "          \"孫女\", \"女友\", \"少女\", \"阿姨\", \"姑姑\", \"閨密\", \"奶奶\", \"老婆\", \"阿嬤\", \"外婆\",\\\n",
    "          \"堂妹\", \"大嫂\", \"外甥女\", \"媳婦\", \"妻子\" ,\"太太\", \"表姊\", \"嫂嫂\", \"大女兒\",\\\n",
    "          \"小姑\", \"老媽\", \"表姐\", \"堂姐\", \"弟妹\", \"弟媳\", \"祖母\", \"舅媽\", \"繼女\", \"岳母\",\\\n",
    "          \"乾媽\", \"女方\", \"愛女\", \"養母\", \"大姊\", \"兒媳\", \"大姑\", \"前妻\", \"嫂子\", \"繼母\",\\\n",
    "          \"嬸嬸\", \"長女\", \"么女\", \"王女\", \"侄女\", \"伯母\", \"大妹\", \"外孫女\"]\n",
    "male = [\"他\", \"你\", \"男\", \"男生\", \"男孩\", \"男士\", \"男人\", \"男性\"]\n",
    "print(model_tw.most_similar(positive=female, topn = 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case: genderization\n",
    "* 看起來不太管用，因為很可能在文本裡面「他」的數量遠過於「她」，導致算相似度的時候，蔡英文與柯文哲兩個人名都是跟「他」比較接近。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_tw.similarity(\"她\", \"蔡英文\"))\n",
    "print(model_tw.similarity(\"他\", \"蔡英文\"))\n",
    "print(model_tw.similarity(\"它\", \"蔡英文\"))\n",
    "print(model_tw.similarity(\"女\", \"蔡英文\"))\n",
    "print(model_tw.similarity(\"男\", \"蔡英文\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_tw.similarity(\"她\", \"柯文哲\"))\n",
    "print(model_tw.similarity(\"他\", \"柯文哲\"))\n",
    "print(model_tw.similarity(\"女生\", \"柯文哲\"))\n",
    "print(model_tw.similarity(\"男生\", \"柯文哲\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretained GoogleNews\n",
    "Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2017). Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes, 115(16). https://doi.org/10.1073/pnas.1720347115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_en = KeyedVectors.load_word2vec_format(\"../../../Downloads/GoogleNews-vectors-negative300.bin\", binary = True)\n",
    "print(\"Number of words: %d\" % len(model.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case: Ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, v in model.most_similar('ideology', topn = 50):\n",
    "    print(t, \"\\t\\t\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case: Homo\n",
    "\n",
    "## to-do\n",
    "1. Drawing keyword networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating term-to-term network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgedict = dict()\n",
    "nodedict = dict()\n",
    "key = \"甲甲\"\n",
    "res = model_tw.most_similar(key, topn = 300)\n",
    "nodedict[key] = res\n",
    "for k, v in res:\n",
    "    edgedict[key, k] = v\n",
    "    edgedict[k, key] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, v in res:\n",
    "    if key not in nodedict:\n",
    "        res = model_tw.most_similar(key, topn = 300)\n",
    "        nodedict[key] = res\n",
    "        for k, v in res:\n",
    "            edgedict[key, k] = v\n",
    "            edgedict[k, key] = v\n",
    "len(edgedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodedict)\n",
    "nodedict['甲甲']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted(edgedict.items(), key=lambda x: x[1], reverse = True)[:200]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted(edgedict.items(), key=lambda x: x[1], reverse = True)[:50]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
